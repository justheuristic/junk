{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43871e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=6\n",
      "env: TRANSFORMERS_CACHE=/mnt/LLM/hub\n",
      "env: OMP_NUM_THREADS=16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/anaconda3/lib/python3.9/site-packages/transformers/utils/hub.py:123: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=6\n",
    "%env TRANSFORMERS_CACHE=/mnt/LLM/hub\n",
    "%env OMP_NUM_THREADS=16\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import time\n",
    "import random\n",
    "from tqdm.auto import trange\n",
    "import ipynbname  # pip install ipynbname\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "\n",
    "from src.aq import QuantizedLinear\n",
    "\n",
    "\n",
    "torch.set_num_threads(16)\n",
    "torch.backends.cudnn.allow_tf32 = False\n",
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "input_loading_dir = '/extra_disk_1/vahe1994/BRRR/layer10.self_attn.q_proj.input_activation.pt'\n",
    "num_codebooks = 2\n",
    "nbits_per_codebook = 8\n",
    "out_group_size = 1\n",
    "in_group_size = 8\n",
    "batch_size = 16384\n",
    "beam_size = 1\n",
    "rrr_rank = 32\n",
    "beam_search_epochs = 100\n",
    "sparsity_regularizer = 0\n",
    "print_frequency = 10\n",
    "scale_nbits = 0    # 0 means no scales, 16 means no compression;\n",
    "codebook_values_nbits = 16  # less than 16 means we quantize codebooks as well\n",
    "init_max_iter = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7e6156a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjustheuristic\u001b[0m (\u001b[33mrock-and-roll\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jheuristic/GPTAQ_rrr/Notebooks/wandb/run-20240102_072016-u86y6xs9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rock-and-roll/AddQuantization-debug/runs/u86y6xs9' target=\"_blank\">aq_simple_AQ_num_codebooks=2_out_group_size=1_in_group_size=8_nbits_per_codebook=8_beam_search_epochs=100</a></strong> to <a href='https://wandb.ai/rock-and-roll/AddQuantization-debug' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rock-and-roll/AddQuantization-debug' target=\"_blank\">https://wandb.ai/rock-and-roll/AddQuantization-debug</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rock-and-roll/AddQuantization-debug/runs/u86y6xs9' target=\"_blank\">https://wandb.ai/rock-and-roll/AddQuantization-debug/runs/u86y6xs9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m No relevant files were detected in the specified directory. No code will be logged to your run.\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = os.path.join(os.getcwd(), ipynbname.name() + \".ipynb\")\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "run = wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    dir=os.getcwd(),\n",
    "    project=\"AddQuantization-debug\",\n",
    "    entity = \"rock-and-roll\",\n",
    "    save_code=True,\n",
    "    name = f\"{ipynbname.name()}_AQ_{num_codebooks=}_{out_group_size=}_{in_group_size=}_{nbits_per_codebook=}_{beam_search_epochs=}\",\n",
    "    settings=wandb.Settings(code_dir=\".\"),\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"num_codebooks\" : num_codebooks,\n",
    "    \"out_group_size\": out_group_size,\n",
    "    \"in_group_size\": in_group_size,\n",
    "    \"group_size\" : out_group_size * in_group_size,\n",
    "    \"batch_size\" : batch_size,\n",
    "    \"beam_size\" : beam_size,\n",
    "    \"nbits_per_codebook\" : nbits_per_codebook,\n",
    "    \"codebook_values_nbits\": codebook_values_nbits,\n",
    "    \"scale_nbits\": scale_nbits,\n",
    "    \"beam_search_epochs\": beam_search_epochs,\n",
    "    \"sparsity_regularizer\": sparsity_regularizer,\n",
    "    \"rrr_rank\": rrr_rank,\n",
    "    \"init_max_iter\": init_max_iter,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbf7e1f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e84c23d2913049e08057d67f82800537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20ff19637ec34ba8886ff40e9ea42da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Llama-2-70b-hf\", torch_dtype='auto', low_cpu_mem_usage=True)\n",
    "\n",
    "X = torch.load(input_loading_dir, map_location='cpu').float().flatten(0, -2)\n",
    "reference_weight = model.model.layers[10].self_attn.q_proj.weight.detach().to(device).float()\n",
    "\n",
    "XTX = torch.zeros(X.shape[-1], X.shape[-1], device=device, dtype=torch.float64)\n",
    "for i in range(0, len(X), batch_size):\n",
    "    x_batch = X[i: i + batch_size].cuda().double()\n",
    "    XTX.addmm_(x_batch.T, x_batch, alpha=1/len(X))\n",
    "    del x_batch\n",
    "XTX = XTX.float()\n",
    "del X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e8656f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!! RRR RANK = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed12fef0a7524e3bbf0c455505687443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "initializing with kmeans:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/GPTAQ_rrr/Notebooks/../src/aq.py:570: UserWarning: index_reduce() is in beta and the API may change at any time. (Triggered internally at /opt/conda/conda-bld/pytorch_1695392022560/work/aten/src/ATen/native/cuda/Indexing.cu:1193.)\n",
      "  codebook_i, _, _ = fit_kmeans(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG bits: 2.1279296875\n",
      "loss=0.0068659294\t time_on_epoch 0 = 0.47034866688773036\n",
      "loss=0.0038049441\t time_on_epoch 10 = 0.14076759619638324\n",
      "loss=0.0032719078\t time_on_epoch 20 = 0.140756756067276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step only supports monotonically increasing values, use define_metric to set a custom x axis. For details see: https://wandb.me/define-metric\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 0 is less than current step: 1. Dropping entry: {'loss': 0.006865929370745206, '_timestamp': 1704169255.1907425}).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=0.0031104048\t time_on_epoch 30 = 0.14079759689047933\n",
      "loss=0.0030090041\t time_on_epoch 40 = 0.14085792610421777\n",
      "loss=0.0029696115\t time_on_epoch 50 = 0.14074284583330154\n",
      "loss=0.0029664642\t time_on_epoch 60 = 0.14095029700547457\n",
      "loss=0.0029449556\t time_on_epoch 70 = 0.1408701059408486\n",
      "loss=0.0029216796\t time_on_epoch 80 = 0.14093184703961015\n",
      "loss=0.0029125094\t time_on_epoch 90 = 0.14112638588994741\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b9e6e2070f4ab68993d828bf532c16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=0.0021841616\t time_on_epoch 100 = 0.14104199595749378\n",
      "loss=0.0021734770\t time_on_epoch 110 = 0.1407064269296825\n",
      "loss=0.0021719400\t time_on_epoch 120 = 0.14103615563362837\n",
      "loss=0.0021710287\t time_on_epoch 130 = 0.14092997601255774\n",
      "loss=0.0021703476\t time_on_epoch 140 = 0.140886546112597\n",
      "loss=0.0021697919\t time_on_epoch 150 = 0.14096741611137986\n",
      "loss=0.0021693199\t time_on_epoch 160 = 0.14089361624792218\n",
      "loss=0.0021689113\t time_on_epoch 170 = 0.14139958564192057\n",
      "loss=0.0021685567\t time_on_epoch 180 = 0.14104339620098472\n",
      "loss=0.0021682554\t time_on_epoch 190 = 0.14083258667960763\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c49640d06a472292b8f33878d6d4f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=0.0020116357\t time_on_epoch 200 = 0.141018767375499\n",
      "loss=0.0020030833\t time_on_epoch 210 = 0.14083915622904897\n",
      "loss=0.0020018875\t time_on_epoch 220 = 0.14116966631263494\n",
      "loss=0.0020012201\t time_on_epoch 230 = 0.14136980613693595\n",
      "loss=0.0020007471\t time_on_epoch 240 = 0.14109506597742438\n",
      "loss=0.0020003870\t time_on_epoch 250 = 0.14094640593975782\n",
      "loss=0.0020001124\t time_on_epoch 260 = 0.14105019578710198\n",
      "loss=0.0019998809\t time_on_epoch 270 = 0.1407855972647667\n",
      "loss=0.0019997095\t time_on_epoch 280 = 0.14073178684338927\n",
      "loss=0.0019995642\t time_on_epoch 290 = 0.14074815716594458\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00236c9dd23249d1a2264b0d32623e3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=0.0019441461\t time_on_epoch 300 = 0.14089556690305471\n",
      "loss=0.0019385082\t time_on_epoch 310 = 0.14108717627823353\n",
      "loss=0.0019377522\t time_on_epoch 320 = 0.1418600450269878\n",
      "loss=0.0019373201\t time_on_epoch 330 = 0.14099987596273422\n",
      "loss=0.0019370013\t time_on_epoch 340 = 0.14132737554609776\n",
      "loss=0.0019367432\t time_on_epoch 350 = 0.14097792701795697\n",
      "loss=0.0019365274\t time_on_epoch 360 = 0.1407167660072446\n",
      "loss=0.0019363497\t time_on_epoch 370 = 0.1407507872208953\n",
      "loss=0.0019362172\t time_on_epoch 380 = 0.1408348362892866\n",
      "loss=0.0019361535\t time_on_epoch 390 = 0.14073202619329095\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c820000bed1a44b49216d231f5cb931c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=0.0019086780\t time_on_epoch 400 = 0.14102852577343583\n",
      "loss=0.0019044359\t time_on_epoch 410 = 0.14070075610652566\n",
      "loss=0.0019038915\t time_on_epoch 420 = 0.14081126591190696\n",
      "loss=0.0019035815\t time_on_epoch 430 = 0.14158996613696218\n",
      "loss=0.0019033524\t time_on_epoch 440 = 0.1409751968458295\n",
      "loss=0.0019031678\t time_on_epoch 450 = 0.14130343589931726\n",
      "loss=0.0019030173\t time_on_epoch 460 = 0.14079406578093767\n",
      "loss=0.0019029037\t time_on_epoch 470 = 0.14101905561983585\n",
      "loss=0.0019028438\t time_on_epoch 480 = 0.14085278613492846\n",
      "loss=0.0019028805\t time_on_epoch 490 = 0.14104067580774426\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9269ab673240448a879efaea5cb39953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=0.0018868461\t time_on_epoch 500 = 0.14096689596772194\n",
      "loss=0.0018834354\t time_on_epoch 510 = 0.14120643632486463\n",
      "loss=0.0018830216\t time_on_epoch 520 = 0.14085106598213315\n",
      "loss=0.0018827914\t time_on_epoch 530 = 0.1408526566810906\n",
      "loss=0.0018826264\t time_on_epoch 540 = 0.14084624592214823\n",
      "loss=0.0018825031\t time_on_epoch 550 = 0.14081582613289356\n",
      "loss=0.0018824239\t time_on_epoch 560 = 0.1408047671429813\n",
      "loss=0.0018824118\t time_on_epoch 570 = 0.14076677709817886\n",
      "loss=0.0018825246\t time_on_epoch 580 = 0.14083088701590896\n",
      "loss=0.0018828821\t time_on_epoch 590 = 0.14076133631169796\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65eba6976d1d463eb1fa65c84fffd8c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=0.0018722054\t time_on_epoch 600 = 0.1410132572054863\n",
      "loss=0.0018693853\t time_on_epoch 610 = 0.14079836569726467\n",
      "loss=0.0018690574\t time_on_epoch 620 = 0.1412493558600545\n",
      "loss=0.0018688773\t time_on_epoch 630 = 0.1409091972745955\n",
      "loss=0.0018687482\t time_on_epoch 640 = 0.14089863607659936\n",
      "loss=0.0018686490\t time_on_epoch 650 = 0.14081498701125383\n",
      "loss=0.0018685755\t time_on_epoch 660 = 0.14082390582188964\n",
      "loss=0.0018685313\t time_on_epoch 670 = 0.14101921673864126\n",
      "loss=0.0018685275\t time_on_epoch 680 = 0.14097003592178226\n",
      "loss=0.0018685857\t time_on_epoch 690 = 0.14109452720731497\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ec473c1b1144cf4b58edcc8f8b89725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=0.0018612342\t time_on_epoch 700 = 0.14127511624246836\n",
      "loss=0.0018588825\t time_on_epoch 710 = 0.1410245569422841\n",
      "loss=0.0018586225\t time_on_epoch 720 = 0.1408826056867838\n",
      "loss=0.0018584836\t time_on_epoch 730 = 0.14087909599766135\n",
      "loss=0.0018583875\t time_on_epoch 740 = 0.1411249772645533\n",
      "loss=0.0018583188\t time_on_epoch 750 = 0.14113233610987663\n",
      "loss=0.0018582771\t time_on_epoch 760 = 0.14121503569185734\n",
      "loss=0.0018582708\t time_on_epoch 770 = 0.14279864495620131\n",
      "loss=0.0018583182\t time_on_epoch 780 = 0.14098927564918995\n",
      "loss=0.0018584528\t time_on_epoch 790 = 0.14077151706442237\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a663dff6a4984a50a7b9785f4eead9b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=0.0018531749\t time_on_epoch 800 = 0.14108340675011277\n",
      "loss=0.0018511775\t time_on_epoch 810 = 0.14083313709124923\n",
      "loss=0.0018509621\t time_on_epoch 820 = 0.14077292708680034\n",
      "loss=0.0018508461\t time_on_epoch 830 = 0.14111936604604125\n",
      "loss=0.0018507620\t time_on_epoch 840 = 0.1409753169864416\n",
      "loss=0.0018506944\t time_on_epoch 850 = 0.14106252696365118\n",
      "loss=0.0018506385\t time_on_epoch 860 = 0.14094429602846503\n",
      "loss=0.0018505932\t time_on_epoch 870 = 0.14078499702736735\n",
      "loss=0.0018505592\t time_on_epoch 880 = 0.14128152607008815\n",
      "loss=0.0018505392\t time_on_epoch 890 = 0.1409889874048531\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00c63a80341a42bf84944440bdbbfe32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=0.0018467491\t time_on_epoch 900 = 0.14098746608942747\n",
      "loss=0.0018450877\t time_on_epoch 910 = 0.140658896882087\n",
      "loss=0.0018449137\t time_on_epoch 920 = 0.14111529709771276\n",
      "loss=0.0018448209\t time_on_epoch 930 = 0.14112113695591688\n",
      "loss=0.0018447540\t time_on_epoch 940 = 0.14079731702804565\n",
      "loss=0.0018447008\t time_on_epoch 950 = 0.14076189696788788\n",
      "loss=0.0018446578\t time_on_epoch 960 = 0.1407570568844676\n",
      "loss=0.0018446243\t time_on_epoch 970 = 0.14077628683298826\n",
      "loss=0.0018446019\t time_on_epoch 980 = 0.14097715634852648\n",
      "loss=0.0018445937\t time_on_epoch 990 = 0.14090442704036832\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "093e7f640333492f8d02a5bac8480414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "quantized_weight = QuantizedLinear(\n",
    "    XTX=XTX, reference_weight=reference_weight, num_codebooks=num_codebooks,\n",
    "    nbits_per_codebook=nbits_per_codebook, scale_nbits=scale_nbits, rrr_rank=rrr_rank,\n",
    "    out_group_size=out_group_size, in_group_size=in_group_size,\n",
    "    verbose=True, max_iter=init_max_iter,   # faster init, not tested\n",
    ")\n",
    "run.log({\"Avg_bits\": quantized_weight.estimate_nbits_per_parameter()})\n",
    "print(\"AVG bits:\", quantized_weight.estimate_nbits_per_parameter())\n",
    "opt = torch.optim.Adam(quantized_weight.parameters(), lr=1e-4, betas=(0.0, 0.95), amsgrad=True)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    start = time.perf_counter()\n",
    "    delta_weight = (quantized_weight() - reference_weight).double()\n",
    "    loss = (delta_weight @ XTX.double()).flatten() @ delta_weight.flatten() / len(delta_weight)\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    run.log({'loss':loss.item()}, step=epoch)\n",
    "    \n",
    "    if epoch % print_frequency == 0:\n",
    "        print(f\"loss={loss.item():.10f}\\t\",\n",
    "              f\"time_on_epoch {epoch} = {time.perf_counter() - start}\")\n",
    "    if (epoch + 1) % beam_search_epochs == 0:\n",
    "        quantized_weight.beam_search_update_codes_(\n",
    "            XTX, reference_weight, beam_size=beam_size, sparsity_regularizer=sparsity_regularizer,\n",
    "            dim_rng=random.Random(), verbose=True)\n",
    "\n",
    "        if sparsity_regularizer != 0:\n",
    "            sparsity_rate = ((quantized_weight.codes == 0).sum() / quantized_weight.codes.numel()).item()\n",
    "            print(f\"Sparsity rate {sparsity_rate:.5f}\")\n",
    "            run.log({'sparsity rate': sparsity_rate}, step=epoch)\n",
    "            mean_code_nbits = sum(get_mean_nbits_by_codebook(quantized_weight.codes)) / num_codebooks\n",
    "            print(f\"mean_code_nbits {mean_code_nbits:.5f}\")\n",
    "            run.log({'Mean codebook length nbits': mean_code_nbits}, step=epoch)\n",
    "            if in_group_size > 1 and out_group_size > 1:\n",
    "                curr_avg_bits  = calc_avg_bits(num_codebooks, 1, mean_code_nbits,\n",
    "                                     nbits_per_codebook, in_features, out_features, scale_nbits)\n",
    "                run.log({\"Avg_bits\": curr_avg_bits}, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5702df5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
